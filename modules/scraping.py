import streamlit as st
import pandas as pd
from scraping.scraping_fonction import scrape_pages

def run():
    st.title("üï∑Ô∏è Scraping")

    st.write("Scrape automatiquement un site selon une URL et un nombre de pages.")

    # INPUTS UTILISATEUR 
    base_url = st.text_input(
        "URL de base (exemple : https://sn.coinafrique.com/categorie/chiens)",
        value="https://sn.coinafrique.com/categorie/chiens"
    )

    total_pages = st.number_input(
        "Nomber de pages √† scraper",
        min_value=1,
        max_value=50,
        value=2
    )

    #  BOUTON DE SCRAPING 
    if st.button("Lancer le scraping"):
        if not base_url.strip():
            st.error("Veuillez entrer une URL valide.")
        else:
            with st.spinner("Scraping en cours..."):
                df = scrape_pages(base_url, total_pages)

            st.success("Scraping termin√© !")
            st.write(f"Nombre d'annonces trouv√©es : **{len(df)}**")

            st.dataframe(df)

            # T√©l√©chargement CSV
            csv = df.to_csv(index=False).encode("utf-8")
            st.download_button(
                "T√©l√©charger le CSV",
                csv,
                "scraped_data.csv",
                "text/csv"
            )
